{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Business cycle correlations\n",
    "\n",
    "For this exercise, you'll be using macroeconomic data from the folder `data/FRED`.\n",
    "\n",
    "1.  There are seven decade-specific files named `FRED_monthly_19X0.csv` where `X` identifies the decade (`X` takes on the values 5, 6, 7, 8, 9, 0, 1). Write a loop that reads in all seven files as DataFrames and store them in a list.\n",
    "\n",
    "    *Hint:* Recall from the lecture that you should use `pd.read_csv(..., parse_dates=['DATE'])` to automatically parse strings stored in the `DATE` column as dates.\n",
    "2.  Use [`pd.concat()`](https://pandas.pydata.org/docs/reference/api/pandas.concat.html) to concate these data sets into a single `DataFrame` and set the `DATE` column as the index.\n",
    "3.  You realize that your data does not include GDP since this variable is only reported at quarterly frequency.\n",
    "    Load the GDP data from the file `GDP.csv` and merge it with your monthly data using an _inner join_.\n",
    "4.  You want to compute how (percent) changes of the variables in your data correlate with percent changes in GDP.\n",
    "\n",
    "    1. Create a _new_ `DataFrame` which contains the percent changes in CPI and GDP (using \n",
    "    [`pct_change()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pct_change.html),\n",
    "    and the absolute changes for the remaining variables (using \n",
    "    [`diff()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.diff.html)).\n",
    "    2.  Compute the correlation of the percent changes in GDP with the (percent) changes of all other variables using [`corr()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html). What does the sign and magnitude of the correlation coefficient tell you?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "DATA_PATH = '../../data/FRED'\n",
    "df_1950 = pd.read_csv(f'{DATA_PATH}/FRED_monthly_1950.csv', parse_dates=['DATE'])\n",
    "df_1960 = pd.read_csv(f'{DATA_PATH}/FRED_monthly_1960.csv', parse_dates=['DATE'])\n",
    "df_1970 = pd.read_csv(f'{DATA_PATH}/FRED_monthly_1970.csv', parse_dates=['DATE'])\n",
    "df_1980 = pd.read_csv(f'{DATA_PATH}/FRED_monthly_1980.csv', parse_dates=['DATE'])\n",
    "df_1990 = pd.read_csv(f'{DATA_PATH}/FRED_monthly_1990.csv', parse_dates=['DATE'])\n",
    "df_2000 = pd.read_csv(f'{DATA_PATH}/FRED_monthly_2000.csv', parse_dates=['DATE'])\n",
    "df_2010 = pd.read_csv(f'{DATA_PATH}/FRED_monthly_2010.csv', parse_dates=['DATE'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((df_1950, df_1960,df_1970,df_1980,df_1990,df_2000,df_2010))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GDP = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Store importted DataFrames in this list\n",
    "data = []\n",
    "for x in range(5, 9):\n",
    "    filename = f'{DATA_PATH}/FRED_monthly_19{x}0.csv'\n",
    "    df = pd.read_csv(filename, parse_dates=['DATE'])\n",
    "    #Add DataFrame to list\n",
    "    data.append(df)\n",
    "for x in range(0, 2):\n",
    "    filename = f'{DATA_PATH}/FRED_monthly_19{x}0.csv'\n",
    "    df = pd.read_csv(filename, parse_dates=['DATE'])\n",
    "    #Add DataFrame to list\n",
    "    data.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for x in range(1950, 2011, 10):\n",
    "    filename = f'{DATA_PATH}/FRED_monthly_{x}.csv'\n",
    "    df = pd.read_csv(filename, parse_dates=['DATE'])\n",
    "    #Add DataFrame to list\n",
    "    data.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    pd.read_csv(f'{DATA_PATH}/FRED_monthly_{x}.csv', parse_dates=['DATE'])\n",
    "    for x in range(1950,2011,10)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate into a single DataFrame\n",
    "df = pd.concat(data, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the DATE column as the index\n",
    "df = df.set_index('DATE')\n",
    "df.loc['1950']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>GDP</th>\n",
       "      <th>CPI</th>\n",
       "      <th>UNRATE</th>\n",
       "      <th>FEDFUNDS</th>\n",
       "      <th>REALRATE</th>\n",
       "      <th>LFPART</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>7341.6</td>\n",
       "      <td>78.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>13.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-04-01</td>\n",
       "      <td>7190.3</td>\n",
       "      <td>80.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>17.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-07-01</td>\n",
       "      <td>7181.7</td>\n",
       "      <td>82.6</td>\n",
       "      <td>7.8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATE     GDP   CPI  UNRATE  FEDFUNDS  REALRATE  LFPART\n",
       "0 1980-01-01  7341.6  78.0     6.3      13.8       NaN    64.0\n",
       "1 1980-04-01  7190.3  80.9     6.9      17.6       NaN    63.8\n",
       "2 1980-07-01  7181.7  82.6     7.8       9.0       NaN    63.8"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "DATA_PATH = '../../data/FRED'\n",
    "df_gdp = pd.read_csv(f'{DATA_PATH}/GDP.csv', parse_dates=['DATE'])\n",
    "df_gdp.set_index('DATE', inplace=True)\n",
    "\n",
    "df_gdp.merge(df, on='DATE').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(df_gdp, df, on='DATE', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = df.join(df_gdp, how='inner',on='DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>CPI</th>\n",
       "      <th>UNRATE</th>\n",
       "      <th>FEDFUNDS</th>\n",
       "      <th>REALRATE</th>\n",
       "      <th>LFPART</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>78.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>13.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>7341.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-04-01</td>\n",
       "      <td>80.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>17.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.8</td>\n",
       "      <td>7190.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1980-07-01</td>\n",
       "      <td>82.6</td>\n",
       "      <td>7.8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.8</td>\n",
       "      <td>7181.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATE   CPI  UNRATE  FEDFUNDS  REALRATE  LFPART     GDP\n",
       "0 1980-01-01  78.0     6.3      13.8       NaN    64.0  7341.6\n",
       "3 1980-04-01  80.9     6.9      17.6       NaN    63.8  7190.3\n",
       "6 1980-07-01  82.6     7.8       9.0       NaN    63.8  7181.7"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute percent changes in CPI and GDP\n",
    "df_changes = df_merge[['CPI','GDP']].pct_change() * 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['UNRATE', 'FEDFUNDS', 'LFPART']\n",
    "\n",
    "#Compute absolute differences and store them in df_changes\n",
    "\n",
    "df_changes[variables] = df_merge[variables].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CPI        -0.281093\n",
       "GDP         1.000000\n",
       "UNRATE     -0.695674\n",
       "FEDFUNDS    0.386210\n",
       "LFPART      0.062576\n",
       "Name: GDP, dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute pairwise correlations\n",
    "df_changes.corr().loc['GDP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Exercise 2: Loading many data files\n",
    "\n",
    "In the previous exercise, you loaded the individual files by specifing an explicit list of file names. This can become tedious or infeasible if your data is spread across many files with varying file name patterns. Python offers the possibility to iterate over all files in a directory (for example, using [`os.listdir()`](https://docs.python.org/3/library/os.html#os.listdir)),\n",
    "or to iterate over files that match a pattern, for example using [`glob.glob()`](https://docs.python.org/3/library/glob.html).\n",
    "\n",
    "Repeat parts (1) and (2) from the previous exercise, but now iterate over the input files using \n",
    "[`glob.glob()`](https://docs.python.org/3/library/glob.html). You'll need to use a wildcard `*` and make sure to match only the relevant files in `data/FRED`, i.e., those that start with `FRED_monthly_1` or `FRED_monthly_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../data/FRED\\\\FRED_monthly_1950.csv',\n",
       " '../../data/FRED\\\\FRED_monthly_1960.csv',\n",
       " '../../data/FRED\\\\FRED_monthly_1970.csv',\n",
       " '../../data/FRED\\\\FRED_monthly_1980.csv',\n",
       " '../../data/FRED\\\\FRED_monthly_1990.csv',\n",
       " '../../data/FRED\\\\FRED_monthly_2000.csv',\n",
       " '../../data/FRED\\\\FRED_monthly_2010.csv']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "pattern = f'{DATA_PATH}/FRED_monthly_[12]*.csv'\n",
    "\n",
    "import glob \n",
    "\n",
    "glob.glob(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file ../../data/FRED\\FRED_monthly_1950.csv\n",
      "Processing file ../../data/FRED\\FRED_monthly_1960.csv\n",
      "Processing file ../../data/FRED\\FRED_monthly_1970.csv\n",
      "Processing file ../../data/FRED\\FRED_monthly_1980.csv\n",
      "Processing file ../../data/FRED\\FRED_monthly_1990.csv\n",
      "Processing file ../../data/FRED\\FRED_monthly_2000.csv\n",
      "Processing file ../../data/FRED\\FRED_monthly_2010.csv\n"
     ]
    }
   ],
   "source": [
    "#List to hold imported data frame\n",
    "data = []\n",
    "\n",
    "for file in glob.glob(pattern):\n",
    "    print(f'Processing file {file}')\n",
    "    df = pd.read_csv(file)\n",
    "    data.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge this to singe DataFrame\n",
    "df = pd.concat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>CPI</th>\n",
       "      <th>UNRATE</th>\n",
       "      <th>FEDFUNDS</th>\n",
       "      <th>REALRATE</th>\n",
       "      <th>LFPART</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1950-01-01</td>\n",
       "      <td>23.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1950-02-01</td>\n",
       "      <td>23.6</td>\n",
       "      <td>6.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1950-03-01</td>\n",
       "      <td>23.6</td>\n",
       "      <td>6.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1950-04-01</td>\n",
       "      <td>23.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1950-05-01</td>\n",
       "      <td>23.8</td>\n",
       "      <td>5.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>256.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>63.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>256.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>63.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>257.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>63.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>257.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>63.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>258.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>63.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>840 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           DATE    CPI  UNRATE  FEDFUNDS  REALRATE  LFPART\n",
       "0    1950-01-01   23.5     6.5       NaN       NaN    58.9\n",
       "1    1950-02-01   23.6     6.4       NaN       NaN    58.9\n",
       "2    1950-03-01   23.6     6.3       NaN       NaN    58.8\n",
       "3    1950-04-01   23.6     5.8       NaN       NaN    59.2\n",
       "4    1950-05-01   23.8     5.5       NaN       NaN    59.1\n",
       "..          ...    ...     ...       ...       ...     ...\n",
       "835  2019-08-01  256.0     3.6       2.1       0.6    63.1\n",
       "836  2019-09-01  256.4     3.5       2.0       0.3    63.2\n",
       "837  2019-10-01  257.2     3.6       1.8      -0.0    63.3\n",
       "838  2019-11-01  257.9     3.6       1.6      -0.2    63.3\n",
       "839  2019-12-01  258.6     3.6       1.6      -0.3    63.3\n",
       "\n",
       "[840 rows x 6 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('DATE').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPI</th>\n",
       "      <th>UNRATE</th>\n",
       "      <th>FEDFUNDS</th>\n",
       "      <th>REALRATE</th>\n",
       "      <th>LFPART</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1950-01-01</th>\n",
       "      <td>23.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-02-01</th>\n",
       "      <td>23.6</td>\n",
       "      <td>6.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-03-01</th>\n",
       "      <td>23.6</td>\n",
       "      <td>6.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-04-01</th>\n",
       "      <td>23.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-05-01</th>\n",
       "      <td>23.8</td>\n",
       "      <td>5.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01</th>\n",
       "      <td>256.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>63.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-01</th>\n",
       "      <td>256.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>63.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01</th>\n",
       "      <td>257.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>63.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01</th>\n",
       "      <td>257.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>63.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01</th>\n",
       "      <td>258.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>63.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>840 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              CPI  UNRATE  FEDFUNDS  REALRATE  LFPART\n",
       "DATE                                                 \n",
       "1950-01-01   23.5     6.5       NaN       NaN    58.9\n",
       "1950-02-01   23.6     6.4       NaN       NaN    58.9\n",
       "1950-03-01   23.6     6.3       NaN       NaN    58.8\n",
       "1950-04-01   23.6     5.8       NaN       NaN    59.2\n",
       "1950-05-01   23.8     5.5       NaN       NaN    59.1\n",
       "...           ...     ...       ...       ...     ...\n",
       "2019-08-01  256.0     3.6       2.1       0.6    63.1\n",
       "2019-09-01  256.4     3.5       2.0       0.3    63.2\n",
       "2019-10-01  257.2     3.6       1.8      -0.0    63.3\n",
       "2019-11-01  257.9     3.6       1.6      -0.2    63.3\n",
       "2019-12-01  258.6     3.6       1.6      -0.3    63.3\n",
       "\n",
       "[840 rows x 5 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index('DATE').sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Exercise 3: Weekly returns of the magnificent seven\n",
    "\n",
    "In this exercise, you are asked to analyze the weekly stockmarket returns\n",
    "of the so-called magnificent 7 which are some of the most successful tech companies \n",
    "of the last decades years:\n",
    "Apple (AAPL), Amazon (AMZN), Alphabet/Google (GOOGL), Meta (META), Microsoft (MSFT), Nvidia (NVDA), and Tesla (TSLA).\n",
    "\n",
    "The data for this exercise is located in the folder `data/stockmarket/`.\n",
    "\n",
    "1.  For each of the seven stocks listed above, there is a corresponding \n",
    "    CSV file in this directory (based on the ticker symbol).\n",
    "\n",
    "    1.  For each ticker symbol, load the corresponding CSV file and make sure \n",
    "        that the `Date` is set as the index.\n",
    "\n",
    "        The DataFrame has two columns, `Open` and `Close`, which contain the \n",
    "        opening and closing price for each trading day.\n",
    "\n",
    "    3.  Use [`resample()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html)\n",
    "        to resample the daily data to a weekly frequency by specifying `resample('W')`,\n",
    "        and compute the weekly returns in percent:\n",
    "\n",
    "        $$\n",
    "        \\text{Weekly returns} = \\frac{\\text{Close price on last day} - \\text{Open price on first day}}{\\text{Open price on first day}} \\times 100\n",
    "        $$\n",
    "\n",
    "        *Hint:* You can obtain the first and last observation using the \n",
    "        [`first()`](https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.first.html) and \n",
    "        [`last()`](https://pandas.pydata.org/docs/reference/api/pandas.core.resample.Resampler.last.html)\n",
    "        methods.\n",
    "\n",
    "    4.  Append these returns to a list so you can merge them into a single DataFrame later.\n",
    "\n",
    "2.  Merge the list of weekly returns you computed into a single DataFrame.\n",
    "    Keep only the intersection of dates available for all 7 stocks.\n",
    "\n",
    "    *Hint:* This can be achieved using either \n",
    "    [`pd.concat()`](https://pandas.pydata.org/docs/reference/api/pandas.concat.html),\n",
    "    [`pd.merge()`](https://pandas.pydata.org/docs/reference/api/pandas.merge.html), or \n",
    "    [`DataFrame.join()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html).\n",
    "\n",
    "3.  Finally, you are interested in how the weekly returns are correlated across \n",
    "    the 7 stocks. \n",
    "\n",
    "    1.  Compute and report the pairwise correlations using \n",
    "        [DataFrame.corr()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html).\n",
    "\n",
    "    2.  Create a figure with 7-by-7 subplots showing the pairwise scatter plots of weekly returns \n",
    "        for each combination of stocks.\n",
    "\n",
    "        You can do this either with the\n",
    "        [`scatter_matrix()`](https://pandas.pydata.org/docs/reference/api/pandas.plotting.scatter_matrix.html) function contained in `pandas.plotting`, \n",
    "        or manually build the figure using Matplotlib functions.\n",
    "\n",
    "    3.  **[Advanced]**\n",
    "        In each of the subplots, add a text that reports the pairwise correlation\n",
    "        for these stocks which you computed earlier.\n",
    "        (e.g., the correlation between returns on AAPL and AMZN is about 0.42,\n",
    "        so this text should be added to the subplot showing the \n",
    "        scatter plot of AAPL vs. AMZN).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-12-12</th>\n",
       "      <td>0.0985</td>\n",
       "      <td>0.0985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-15</th>\n",
       "      <td>0.0938</td>\n",
       "      <td>0.0933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-16</th>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.0865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-17</th>\n",
       "      <td>0.0886</td>\n",
       "      <td>0.0886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-18</th>\n",
       "      <td>0.0912</td>\n",
       "      <td>0.0912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-23</th>\n",
       "      <td>253.8688</td>\n",
       "      <td>254.3670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-24</th>\n",
       "      <td>254.5862</td>\n",
       "      <td>257.2867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-26</th>\n",
       "      <td>257.2767</td>\n",
       "      <td>258.1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-27</th>\n",
       "      <td>256.9179</td>\n",
       "      <td>254.6859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-30</th>\n",
       "      <td>251.3378</td>\n",
       "      <td>251.3079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11104 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open     Close\n",
       "Date                          \n",
       "1980-12-12    0.0985    0.0985\n",
       "1980-12-15    0.0938    0.0933\n",
       "1980-12-16    0.0869    0.0865\n",
       "1980-12-17    0.0886    0.0886\n",
       "1980-12-18    0.0912    0.0912\n",
       "...              ...       ...\n",
       "2024-12-23  253.8688  254.3670\n",
       "2024-12-24  254.5862  257.2867\n",
       "2024-12-26  257.2767  258.1037\n",
       "2024-12-27  256.9179  254.6859\n",
       "2024-12-30  251.3378  251.3079\n",
       "\n",
       "[11104 rows x 2 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = '../../data/stockmarket'\n",
    "\n",
    "fn = pd.read_csv(f'{DATA_PATH}/AAPL.csv')\n",
    "fn.set_index('Date', inplace=True)\n",
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file ../../data/stockmarket/AAPL.csv\n",
      "Processing file ../../data/stockmarket/AMZN.csv\n",
      "Processing file ../../data/stockmarket/DJIA.csv\n",
      "Processing file ../../data/stockmarket/GOOGL.csv\n",
      "Processing file ../../data/stockmarket/indices.csv\n",
      "Processing file ../../data/stockmarket/META.csv\n",
      "Processing file ../../data/stockmarket/MSFT.csv\n",
      "Processing file ../../data/stockmarket/NASDAQ.csv\n",
      "Processing file ../../data/stockmarket/NVDA.csv\n",
      "Processing file ../../data/stockmarket/SP500.csv\n",
      "Processing file ../../data/stockmarket/TSLA.csv\n"
     ]
    }
   ],
   "source": [
    "# list to hold processed data for each stock\n",
    "data = []\n",
    "#Loop over ticker symbols and perform task in part 1\n",
    "tickers = ['AAPL', 'AMZN', 'DJIA', 'GOOGL', 'indices', 'META', 'MSFT','NASDAQ', 'NVDA', 'SP500', 'TSLA']\n",
    "\n",
    "for t in tickers:\n",
    "    filename = f'{DATA_PATH}/{t}.csv'\n",
    "    print(f'Processing file {filename}')\n",
    "    df = pd.read_csv(filename, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-06-29</th>\n",
       "      <td>1.2667</td>\n",
       "      <td>1.5927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30</th>\n",
       "      <td>1.7193</td>\n",
       "      <td>1.5887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-01</th>\n",
       "      <td>1.6667</td>\n",
       "      <td>1.4640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-02</th>\n",
       "      <td>1.5333</td>\n",
       "      <td>1.2800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-06</th>\n",
       "      <td>1.3333</td>\n",
       "      <td>1.0740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-23</th>\n",
       "      <td>431.0000</td>\n",
       "      <td>430.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-24</th>\n",
       "      <td>435.9000</td>\n",
       "      <td>462.2800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-26</th>\n",
       "      <td>465.1600</td>\n",
       "      <td>454.1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-27</th>\n",
       "      <td>449.5200</td>\n",
       "      <td>431.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-30</th>\n",
       "      <td>419.4000</td>\n",
       "      <td>417.4100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3651 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open     Close\n",
       "Date                          \n",
       "2010-06-29    1.2667    1.5927\n",
       "2010-06-30    1.7193    1.5887\n",
       "2010-07-01    1.6667    1.4640\n",
       "2010-07-02    1.5333    1.2800\n",
       "2010-07-06    1.3333    1.0740\n",
       "...              ...       ...\n",
       "2024-12-23  431.0000  430.6000\n",
       "2024-12-24  435.9000  462.2800\n",
       "2024-12-26  465.1600  454.1300\n",
       "2024-12-27  449.5200  431.6600\n",
       "2024-12-30  419.4000  417.4100\n",
       "\n",
       "[3651 rows x 2 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['Date'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_2752\\3064852677.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df.set_index(\u001b[33m'Date'\u001b[39m, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[32mc:\\Users\\jsaet\\anaconda3\\envs\\TECH2\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, keys, drop, append, inplace, verify_integrity)\u001b[39m\n\u001b[32m   6125\u001b[39m                     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m found:\n\u001b[32m   6126\u001b[39m                         missing.append(col)\n\u001b[32m   6127\u001b[39m \n\u001b[32m   6128\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[32m-> \u001b[39m\u001b[32m6129\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(f\"None of {missing} are in the columns\")\n\u001b[32m   6130\u001b[39m \n\u001b[32m   6131\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   6132\u001b[39m             frame = self\n",
      "\u001b[31mKeyError\u001b[39m: \"None of ['Date'] are in the columns\""
     ]
    }
   ],
   "source": [
    "df.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[113]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m last = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mW\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mClose\u001b[39m\u001b[33m'\u001b[39m].last()\n\u001b[32m      2\u001b[39m first = df.resample(\u001b[33m'\u001b[39m\u001b[33mW\u001b[39m\u001b[33m'\u001b[39m)[\u001b[33m'\u001b[39m\u001b[33mOpen\u001b[39m\u001b[33m'\u001b[39m].first()\n\u001b[32m      4\u001b[39m returns = (last - first ) / first * \u001b[32m100.0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jsaet\\anaconda3\\envs\\TECH2\\Lib\\site-packages\\pandas\\core\\generic.py:9790\u001b[39m, in \u001b[36mNDFrame.resample\u001b[39m\u001b[34m(self, rule, axis, closed, label, convention, kind, on, level, origin, offset, group_keys)\u001b[39m\n\u001b[32m   9787\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   9788\u001b[39m     convention = \u001b[33m\"\u001b[39m\u001b[33mstart\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m9790\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_resampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   9791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSeries | DataFrame\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfreq\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclosed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9795\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvention\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9799\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9800\u001b[39m \u001b[43m    \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m=\u001b[49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9801\u001b[39m \u001b[43m    \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9802\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9803\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jsaet\\anaconda3\\envs\\TECH2\\Lib\\site-packages\\pandas\\core\\resample.py:2050\u001b[39m, in \u001b[36mget_resampler\u001b[39m\u001b[34m(obj, kind, **kwds)\u001b[39m\n\u001b[32m   2046\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2047\u001b[39m \u001b[33;03mCreate a TimeGrouper and return our resampler.\u001b[39;00m\n\u001b[32m   2048\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2049\u001b[39m tg = TimeGrouper(obj, **kwds)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2050\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtg\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_resampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkind\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jsaet\\anaconda3\\envs\\TECH2\\Lib\\site-packages\\pandas\\core\\resample.py:2272\u001b[39m, in \u001b[36mTimeGrouper._get_resampler\u001b[39m\u001b[34m(self, obj, kind)\u001b[39m\n\u001b[32m   2263\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ax, TimedeltaIndex):\n\u001b[32m   2264\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m TimedeltaIndexResampler(\n\u001b[32m   2265\u001b[39m         obj,\n\u001b[32m   2266\u001b[39m         timegrouper=\u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2269\u001b[39m         gpr_index=ax,\n\u001b[32m   2270\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2272\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   2273\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mOnly valid with DatetimeIndex, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2274\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mTimedeltaIndex or PeriodIndex, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2275\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbut got an instance of \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(ax).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2276\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'"
     ]
    }
   ],
   "source": [
    "last = df.resample('W')['Close'].last()\n",
    "first = df.resample('W')['Open'].first()\n",
    "\n",
    "returns = (last - first ) / first * 100.0\n",
    "\n",
    "data.append(returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Exercise 4: Decade averages of macro time series\n",
    "\n",
    "\n",
    "For this exercise, you'll be using macroeconomic data from the folder `data/FRED`.\n",
    "\n",
    "1.  There are five files containing monthly observations on annual inflation (INFLATION), the Fed Funds rate (FEDFUNDS), the labor force participation rate (LFPART), the 1-year real interest rate (REALRATE) and the unemployment rate (UNRATE).\n",
    "\n",
    "    1.  Write a loop to import these files and store the individual DataFrames in a list.\n",
    "\n",
    "        *Hint:* Recall from the lecture that you should use \n",
    "        `pd.read_csv(..., parse_dates=['DATE'], index_col='DATE')` to automatically parse strings stored in the `DATE` column as dates and set the `DATE`\n",
    "        column as the index.\n",
    "\n",
    "    2.  Use \n",
    "        [`pd.concat()`](https://pandas.pydata.org/docs/reference/api/pandas.concat.html)\n",
    "        to concatenate this list of DataFrames along the column dimension\n",
    "        using an outer join (`join='outer'`) to obtain a merged data set.\n",
    "\n",
    "3.  You want to compute the average value of each variable by decade, but you want to include only decades without _any_ missing values for _all_ variables.\n",
    "\n",
    "    1.  Create a variable `Decade` which stores the decade (1940, 1950, ...) for each observation.\n",
    "\n",
    "        *Hint:* You should have set the `DATE` as the `DataFrame` index. Then you can access the calendar year using the attribute `df.index.year` which can be used to compute the decade.\n",
    "\n",
    "    2.  Create an indicator variable which takes on the value `True` \n",
    "        whenever all observations (all columns) for a given date are non-missing, and `False`\n",
    "        if at least one variable has a missing observation. \n",
    "\n",
    "    3.  Aggregate this indicator to decades using a\n",
    "    [`groupby()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html) so that the indicator takes on the value `True` whenever\n",
    "    _all_ variables in a given decade have no missing values, and `False`\n",
    "    otherwise.\n",
    "\n",
    "        *Hint:* You can use the \n",
    "        [`all()`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.all.html) aggregation for this.\n",
    "\n",
    "    4.  Merge this decade-level indicator data back into the original `DataFrame` (_many-to-one_ merge). \n",
    "4.  Using this indicator, drop all observations which are in a decade with missing values.\n",
    "5.  Compute the decade average for each variable.\n",
    "\n",
    "**Challenge**\n",
    "\n",
    "-   Your pandas guru friend claims that all the steps in 2.2 to 2.4 can be done with a single one-liner using [`transform()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.transform.html). Can you come up with a solution?\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Exercise 5: Merging additional Titanic data\n",
    "\n",
    "In this exercise, you'll be working with the the original Titanic data set in `titanic.csv` and additional (partly fictitious) information on passengers stored in `titanic-additional.csv`, both located in the `data/` folder.\n",
    "\n",
    "The goal of the exercise is to calculate the survival rates by country of residence (for this exercise we restrict ourselves to the UK, so these will be England, Scotland, etc.).\n",
    "\n",
    "1.  Load the `titanic.csv` and `titanic-additional.csv` into two DataFrames.\n",
    "\n",
    "    Inspect the columns contained in both data sets. As you can see, the original data contains the full name including the title\n",
    "    and potentially maiden name (for married women) in a single column.\n",
    "    The additional data contains this information in separate columns.\n",
    "    You want to merge these data sets, but you first need to create common keys in both DataFrames.\n",
    "\n",
    "2.  Since the only common information is the name, you'll need to extract the individual name components from the original DataFrame\n",
    "    and use these as merge keys.\n",
    "\n",
    "    Focusing only on men (who have names that are much easier to parse), split the `Name` column into the tokens \n",
    "    `Title`, `FirstName` and `LastName`, just like the columns in the second DataFrame.\n",
    "\n",
    "    *Hint:* This is the same task as in the last exercise in Workshop 2. You can just use your solution here.\n",
    "\n",
    "3.  Merge the two data sets based on the columns `Title`, `FirstName` and `LastName` you just created using a _left join_ (_one-to-one_ merge).\n",
    "    Tabulate the columns and the number of non-missing observations to make sure that merging worked. \n",
    "\n",
    "    *Note:* The additional data set contains address information only for passengers from the UK, so some of these fields will be missing.\n",
    "\n",
    "4.  You are now in a position to merge the country of residence (_many-to-one_ merge). Load the country data from `UK_post_codes.csv` which contains \n",
    "    the UK post code prefix (which you can ignore), the corresponding city, and the corresponding country.\n",
    "\n",
    "    Merge this data with your passenger data set using a _left join_ (what is the correct merge key?).\n",
    "\n",
    "5.  Tabulate the number of observations by `Country`, including the number of observations with missing `Country` (these are passengers residing outside the UK).\n",
    "\n",
    "    Finally, compute the mean survival rate by country."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TECH2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
